{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "check.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO83GbJolxJBUOuNkSMRJZD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadShaheer-khan/check/blob/master/check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-OoshCcpcyT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "06a87985-f72e-4789-c712-0dc232bc1534"
      },
      "source": [
        "# To determine which version you're using:\n",
        "!pip show tensorflow\n",
        "\n",
        "# For the current version: \n",
        "!pip install --upgrade tensorflow\n",
        "\n",
        "# For a specific version:\n",
        "!pip install tensorflow==1.2\n",
        "\n",
        "# For the latest nightly build:\n",
        "!pip install tf-nightly"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.2.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: protobuf, six, numpy, h5py, opt-einsum, wrapt, scipy, tensorflow-estimator, grpcio, tensorboard, keras-preprocessing, absl-py, google-pasta, gast, termcolor, wheel, astunparse\n",
            "Required-by: fancyimpute\n",
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.2)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.30.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (47.3.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.1)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.1.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
            "Collecting tensorflow==1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/55/7995cc1e9e60fa37ea90e6777d832e75026fde5c6109215d892aaff2e9b7/tensorflow-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (35.0MB)\n",
            "\u001b[K     |████████████████████████████████| 35.0MB 72.9MB/s \n",
            "\u001b[?25hCollecting markdown==2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/99/288a81a38526a42c98b5b9832c6e339ca8d5dd38b19a53abfac7c8037c7f/Markdown-2.2.0.tar.gz (236kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 48.7MB/s \n",
            "\u001b[?25hCollecting backports.weakref==1.0rc1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/f7/ae34b6818b603e264f26fe7db2bd07850ce331ce2fde74b266d61f4a2d87/backports.weakref-1.0rc1-py3-none-any.whl\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.18.5)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (3.10.0)\n",
            "Collecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (0.34.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorflow==1.2) (47.3.1)\n",
            "Building wheels for collected packages: markdown, html5lib\n",
            "  Building wheel for markdown (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markdown: filename=Markdown-2.2.0-cp36-none-any.whl size=136298 sha256=1844b79eeaa3e174b40fcd4ed69e6daaa4df18738ae913ec37e1b7b75dd49ddd\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/52/17/f0af18e3e0ec6fa60b361ffed15b4c3468f6f3bcdb87fbe079\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107220 sha256=bf5b0e74468a54e8e5909a4b656f3327cd3b4ffcb6fb28c2b134c19d55e4510e\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built markdown html5lib\n",
            "\u001b[31mERROR: tensorboard 2.2.2 has requirement markdown>=2.6.8, but you'll have markdown 2.2.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: markdown, backports.weakref, html5lib, bleach, tensorflow\n",
            "  Found existing installation: Markdown 3.2.2\n",
            "    Uninstalling Markdown-3.2.2:\n",
            "      Successfully uninstalled Markdown-3.2.2\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.1.5\n",
            "    Uninstalling bleach-3.1.5:\n",
            "      Successfully uninstalled bleach-3.1.5\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed backports.weakref-1.0rc1 bleach-1.5.0 html5lib-0.9999999 markdown-2.2.0 tensorflow-1.2.0\n",
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/07/793d3582046b29d13e1a499bdef546e1f0b6c92ab9273d3b6516c5f5ee11/tf_nightly-2.4.0.dev20200708-cp36-cp36m-manylinux2010_x86_64.whl (322.8MB)\n",
            "\u001b[K     |████████████████████████████████| 322.8MB 49kB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.9.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.4.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.2)\n",
            "Collecting tf-estimator-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/ab/a4f76db321f383c057671e21b2a4afb295fb0c0546eb83aaccef4b10e57c/tf_estimator_nightly-2.4.0.dev2020070801-py2.py3-none-any.whl (459kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 44.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.34.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.3.3)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.18.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.2.1)\n",
            "Collecting tb-nightly<2.4.0a0,>=2.3.0a0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/87/63958c64138e3f5cabe3aeaff33decdeea4731423cac4c934ad1e7b032ea/tb_nightly-2.3.0a20200708-py3-none-any.whl (6.5MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 19.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.30.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.10.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.6.0.post3)\n",
            "Collecting markdown>=2.6.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/63/eaec2bd025ab48c754b55e8819af0f6a69e2b1e187611dd40cbbe101ee7f/Markdown-3.2.2-py3-none-any.whl (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (47.3.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (4.1.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.6.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.0)\n",
            "\u001b[31mERROR: tensorflow 1.2.0 has requirement markdown==2.2.0, but you'll have markdown 3.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tf-estimator-nightly, markdown, tb-nightly, tf-nightly\n",
            "  Found existing installation: Markdown 2.2.0\n",
            "    Uninstalling Markdown-2.2.0:\n",
            "      Successfully uninstalled Markdown-2.2.0\n",
            "Successfully installed markdown-3.2.2 tb-nightly-2.3.0a20200708 tf-estimator-nightly-2.4.0.dev2020070801 tf-nightly-2.4.0.dev20200708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-njIUnRApsWP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "674ded4f-a465-4c05-9f81-4de23acbc4c1"
      },
      "source": [
        "pip install ta"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ta\n",
            "  Downloading https://files.pythonhosted.org/packages/90/ec/e4f5aea8c7f0f55f92b52ffbafa389ea82f3a10d9cab2760e40af34c5b3f/ta-0.5.25.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ta) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ta) (1.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->ta) (1.12.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.5.25-cp36-none-any.whl size=24880 sha256=d8b1c5f531041ae5cf93ed74095ffc6886c34d4e594486c490fe9eb51c7a2dbd\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/93/b7/cf649194508e53cee4145ffb949e9f26877a5a8dd12db9ed5b\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.5.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HQSTinkpj-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1e6cf54-be32-4edb-91dd-b8f13af700ef"
      },
      "source": [
        "# Importing Libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "plt.style.use(\"bmh\")\n",
        "\n",
        "\n",
        "import ta\n",
        "\n",
        "# Neural Network library\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bir0PUjpy__",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4ad19ad1-4aca-452f-bb3b-376523341695"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['SPY.csv']))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-16fe7287-4581-479a-9538-7bbac9b643fc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-16fe7287-4581-479a-9538-7bbac9b643fc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving SPY.csv to SPY.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfXnKbYzqTLQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bc7258f9-4e74-4ce1-c3bf-80f26abde91d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-07-08</td>\n",
              "      <td>297.010010</td>\n",
              "      <td>298.260010</td>\n",
              "      <td>296.220001</td>\n",
              "      <td>296.820007</td>\n",
              "      <td>291.010712</td>\n",
              "      <td>45841800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-07-09</td>\n",
              "      <td>295.540009</td>\n",
              "      <td>297.519989</td>\n",
              "      <td>295.480011</td>\n",
              "      <td>297.190002</td>\n",
              "      <td>291.373474</td>\n",
              "      <td>41101300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-07-10</td>\n",
              "      <td>298.369995</td>\n",
              "      <td>299.660004</td>\n",
              "      <td>297.779999</td>\n",
              "      <td>298.609985</td>\n",
              "      <td>292.765656</td>\n",
              "      <td>58448500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-07-11</td>\n",
              "      <td>299.320007</td>\n",
              "      <td>299.579987</td>\n",
              "      <td>298.200012</td>\n",
              "      <td>299.309998</td>\n",
              "      <td>293.451996</td>\n",
              "      <td>50826100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-07-12</td>\n",
              "      <td>299.850006</td>\n",
              "      <td>300.730011</td>\n",
              "      <td>299.510010</td>\n",
              "      <td>300.649994</td>\n",
              "      <td>294.765747</td>\n",
              "      <td>40326000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date        Open        High  ...       Close   Adj Close    Volume\n",
              "0  2019-07-08  297.010010  298.260010  ...  296.820007  291.010712  45841800\n",
              "1  2019-07-09  295.540009  297.519989  ...  297.190002  291.373474  41101300\n",
              "2  2019-07-10  298.369995  299.660004  ...  298.609985  292.765656  58448500\n",
              "3  2019-07-11  299.320007  299.579987  ...  299.309998  293.451996  50826100\n",
              "4  2019-07-12  299.850006  300.730011  ...  300.649994  294.765747  40326000\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuG3ttBTvXOV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e6847090-93d4-4a80-8736-da2570e9c81c"
      },
      "source": [
        "# after conversion\n",
        "\n",
        "df.info()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 251 entries, 2019-07-08 to 2020-07-02\n",
            "Data columns (total 73 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   Close                      251 non-null    float64\n",
            " 1   volume_adi                 251 non-null    float64\n",
            " 2   volume_obv                 251 non-null    float64\n",
            " 3   volume_cmf                 251 non-null    float64\n",
            " 4   volume_fi                  251 non-null    float64\n",
            " 5   momentum_mfi               251 non-null    float64\n",
            " 6   volume_em                  251 non-null    float64\n",
            " 7   volume_sma_em              251 non-null    float64\n",
            " 8   volume_vpt                 251 non-null    float64\n",
            " 9   volume_nvi                 251 non-null    float64\n",
            " 10  volume_vwap                251 non-null    float64\n",
            " 11  volatility_atr             251 non-null    float64\n",
            " 12  volatility_bbm             251 non-null    float64\n",
            " 13  volatility_bbh             251 non-null    float64\n",
            " 14  volatility_bbl             251 non-null    float64\n",
            " 15  volatility_bbw             251 non-null    float64\n",
            " 16  volatility_bbp             251 non-null    float64\n",
            " 17  volatility_bbhi            251 non-null    float64\n",
            " 18  volatility_bbli            251 non-null    float64\n",
            " 19  volatility_kcc             251 non-null    float64\n",
            " 20  volatility_kch             251 non-null    float64\n",
            " 21  volatility_kcl             251 non-null    float64\n",
            " 22  volatility_kcw             251 non-null    float64\n",
            " 23  volatility_kcp             251 non-null    float64\n",
            " 24  volatility_kchi            251 non-null    float64\n",
            " 25  volatility_kcli            251 non-null    float64\n",
            " 26  volatility_dcl             251 non-null    float64\n",
            " 27  volatility_dch             251 non-null    float64\n",
            " 28  trend_macd                 251 non-null    float64\n",
            " 29  trend_macd_signal          251 non-null    float64\n",
            " 30  trend_macd_diff            251 non-null    float64\n",
            " 31  trend_sma_fast             251 non-null    float64\n",
            " 32  trend_sma_slow             251 non-null    float64\n",
            " 33  trend_ema_fast             251 non-null    float64\n",
            " 34  trend_ema_slow             251 non-null    float64\n",
            " 35  trend_adx                  251 non-null    float64\n",
            " 36  trend_adx_pos              251 non-null    float64\n",
            " 37  trend_adx_neg              251 non-null    float64\n",
            " 38  trend_vortex_ind_pos       251 non-null    float64\n",
            " 39  trend_vortex_ind_neg       251 non-null    float64\n",
            " 40  trend_vortex_ind_diff      251 non-null    float64\n",
            " 41  trend_trix                 251 non-null    float64\n",
            " 42  trend_mass_index           251 non-null    float64\n",
            " 43  trend_cci                  251 non-null    float64\n",
            " 44  trend_dpo                  251 non-null    float64\n",
            " 45  trend_kst                  251 non-null    float64\n",
            " 46  trend_kst_sig              251 non-null    float64\n",
            " 47  trend_kst_diff             251 non-null    float64\n",
            " 48  trend_ichimoku_conv        251 non-null    float64\n",
            " 49  trend_ichimoku_base        251 non-null    float64\n",
            " 50  trend_ichimoku_a           251 non-null    float64\n",
            " 51  trend_ichimoku_b           251 non-null    float64\n",
            " 52  trend_visual_ichimoku_a    251 non-null    float64\n",
            " 53  trend_visual_ichimoku_b    251 non-null    float64\n",
            " 54  trend_aroon_up             251 non-null    float64\n",
            " 55  trend_aroon_down           251 non-null    float64\n",
            " 56  trend_aroon_ind            251 non-null    float64\n",
            " 57  trend_psar_up              251 non-null    float64\n",
            " 58  trend_psar_down            251 non-null    float64\n",
            " 59  trend_psar_up_indicator    251 non-null    float64\n",
            " 60  trend_psar_down_indicator  251 non-null    float64\n",
            " 61  momentum_rsi               251 non-null    float64\n",
            " 62  momentum_tsi               251 non-null    float64\n",
            " 63  momentum_uo                251 non-null    float64\n",
            " 64  momentum_stoch             251 non-null    float64\n",
            " 65  momentum_stoch_signal      251 non-null    float64\n",
            " 66  momentum_wr                251 non-null    float64\n",
            " 67  momentum_ao                251 non-null    float64\n",
            " 68  momentum_kama              251 non-null    float64\n",
            " 69  momentum_roc               251 non-null    float64\n",
            " 70  others_dr                  251 non-null    float64\n",
            " 71  others_dlr                 251 non-null    float64\n",
            " 72  others_cr                  251 non-null    float64\n",
            "dtypes: float64(73)\n",
            "memory usage: 145.1 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjACqyG4vZmc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "8580e367-def7-4b3a-be11-9392a9e92f49"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "      <th>volume_adi</th>\n",
              "      <th>volume_obv</th>\n",
              "      <th>volume_cmf</th>\n",
              "      <th>volume_fi</th>\n",
              "      <th>momentum_mfi</th>\n",
              "      <th>volume_em</th>\n",
              "      <th>volume_sma_em</th>\n",
              "      <th>volume_vpt</th>\n",
              "      <th>volume_nvi</th>\n",
              "      <th>volume_vwap</th>\n",
              "      <th>volatility_atr</th>\n",
              "      <th>volatility_bbm</th>\n",
              "      <th>volatility_bbh</th>\n",
              "      <th>volatility_bbl</th>\n",
              "      <th>volatility_bbw</th>\n",
              "      <th>volatility_bbp</th>\n",
              "      <th>volatility_bbhi</th>\n",
              "      <th>volatility_bbli</th>\n",
              "      <th>volatility_kcc</th>\n",
              "      <th>volatility_kch</th>\n",
              "      <th>volatility_kcl</th>\n",
              "      <th>volatility_kcw</th>\n",
              "      <th>volatility_kcp</th>\n",
              "      <th>volatility_kchi</th>\n",
              "      <th>volatility_kcli</th>\n",
              "      <th>volatility_dcl</th>\n",
              "      <th>volatility_dch</th>\n",
              "      <th>trend_macd</th>\n",
              "      <th>trend_macd_signal</th>\n",
              "      <th>trend_macd_diff</th>\n",
              "      <th>trend_sma_fast</th>\n",
              "      <th>trend_sma_slow</th>\n",
              "      <th>trend_ema_fast</th>\n",
              "      <th>trend_ema_slow</th>\n",
              "      <th>trend_adx</th>\n",
              "      <th>trend_adx_pos</th>\n",
              "      <th>trend_adx_neg</th>\n",
              "      <th>trend_vortex_ind_pos</th>\n",
              "      <th>trend_vortex_ind_neg</th>\n",
              "      <th>trend_vortex_ind_diff</th>\n",
              "      <th>trend_trix</th>\n",
              "      <th>trend_mass_index</th>\n",
              "      <th>trend_cci</th>\n",
              "      <th>trend_dpo</th>\n",
              "      <th>trend_kst</th>\n",
              "      <th>trend_kst_sig</th>\n",
              "      <th>trend_kst_diff</th>\n",
              "      <th>trend_ichimoku_conv</th>\n",
              "      <th>trend_ichimoku_base</th>\n",
              "      <th>trend_ichimoku_a</th>\n",
              "      <th>trend_ichimoku_b</th>\n",
              "      <th>trend_visual_ichimoku_a</th>\n",
              "      <th>trend_visual_ichimoku_b</th>\n",
              "      <th>trend_aroon_up</th>\n",
              "      <th>trend_aroon_down</th>\n",
              "      <th>trend_aroon_ind</th>\n",
              "      <th>trend_psar_up</th>\n",
              "      <th>trend_psar_down</th>\n",
              "      <th>trend_psar_up_indicator</th>\n",
              "      <th>trend_psar_down_indicator</th>\n",
              "      <th>momentum_rsi</th>\n",
              "      <th>momentum_tsi</th>\n",
              "      <th>momentum_uo</th>\n",
              "      <th>momentum_stoch</th>\n",
              "      <th>momentum_stoch_signal</th>\n",
              "      <th>momentum_wr</th>\n",
              "      <th>momentum_ao</th>\n",
              "      <th>momentum_kama</th>\n",
              "      <th>momentum_roc</th>\n",
              "      <th>others_dr</th>\n",
              "      <th>others_dlr</th>\n",
              "      <th>others_cr</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-06-26</th>\n",
              "      <td>-0.009386</td>\n",
              "      <td>0.262485</td>\n",
              "      <td>0.161485</td>\n",
              "      <td>-0.412893</td>\n",
              "      <td>-2.776234</td>\n",
              "      <td>-1.244637</td>\n",
              "      <td>-0.759535</td>\n",
              "      <td>-2.915370</td>\n",
              "      <td>-1.473601</td>\n",
              "      <td>1.321035</td>\n",
              "      <td>0.443646</td>\n",
              "      <td>0.696818</td>\n",
              "      <td>0.591734</td>\n",
              "      <td>0.662552</td>\n",
              "      <td>0.345810</td>\n",
              "      <td>0.417876</td>\n",
              "      <td>-1.318727</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.405836</td>\n",
              "      <td>0.596289</td>\n",
              "      <td>0.205485</td>\n",
              "      <td>0.764479</td>\n",
              "      <td>-0.996681</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.422434</td>\n",
              "      <td>-1.428701</td>\n",
              "      <td>0.024148</td>\n",
              "      <td>0.653009</td>\n",
              "      <td>-1.736954</td>\n",
              "      <td>0.384259</td>\n",
              "      <td>0.528883</td>\n",
              "      <td>0.431430</td>\n",
              "      <td>0.439054</td>\n",
              "      <td>-0.562032</td>\n",
              "      <td>-0.553532</td>\n",
              "      <td>0.651590</td>\n",
              "      <td>-0.602056</td>\n",
              "      <td>1.081599</td>\n",
              "      <td>-0.898051</td>\n",
              "      <td>0.744276</td>\n",
              "      <td>0.128762</td>\n",
              "      <td>-1.214537</td>\n",
              "      <td>-2.177401</td>\n",
              "      <td>0.529255</td>\n",
              "      <td>1.061574</td>\n",
              "      <td>-1.696045</td>\n",
              "      <td>0.377603</td>\n",
              "      <td>0.669573</td>\n",
              "      <td>0.495458</td>\n",
              "      <td>0.325464</td>\n",
              "      <td>-0.656118</td>\n",
              "      <td>-4.472616</td>\n",
              "      <td>-0.533333</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>0.017086</td>\n",
              "      <td>0.871993</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.672988</td>\n",
              "      <td>-0.138705</td>\n",
              "      <td>-0.798883</td>\n",
              "      <td>-1.394698</td>\n",
              "      <td>-1.088480</td>\n",
              "      <td>-1.394698</td>\n",
              "      <td>-0.144562</td>\n",
              "      <td>0.700356</td>\n",
              "      <td>-1.926734</td>\n",
              "      <td>-2.097074</td>\n",
              "      <td>-2.159749</td>\n",
              "      <td>-0.009386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-06-29</th>\n",
              "      <td>0.197559</td>\n",
              "      <td>0.407038</td>\n",
              "      <td>0.300251</td>\n",
              "      <td>-0.313903</td>\n",
              "      <td>-1.810644</td>\n",
              "      <td>-1.022246</td>\n",
              "      <td>-0.727064</td>\n",
              "      <td>-3.073069</td>\n",
              "      <td>-1.332893</td>\n",
              "      <td>1.387319</td>\n",
              "      <td>0.402827</td>\n",
              "      <td>0.671718</td>\n",
              "      <td>0.589028</td>\n",
              "      <td>0.664331</td>\n",
              "      <td>0.339536</td>\n",
              "      <td>0.429690</td>\n",
              "      <td>-0.959202</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.399777</td>\n",
              "      <td>0.563344</td>\n",
              "      <td>0.223892</td>\n",
              "      <td>0.611446</td>\n",
              "      <td>-0.668697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.422682</td>\n",
              "      <td>-1.083456</td>\n",
              "      <td>-0.082214</td>\n",
              "      <td>0.521309</td>\n",
              "      <td>-1.680391</td>\n",
              "      <td>0.398834</td>\n",
              "      <td>0.548369</td>\n",
              "      <td>0.408095</td>\n",
              "      <td>0.434941</td>\n",
              "      <td>-0.529577</td>\n",
              "      <td>-0.643088</td>\n",
              "      <td>0.521645</td>\n",
              "      <td>-0.599693</td>\n",
              "      <td>1.145022</td>\n",
              "      <td>-0.929010</td>\n",
              "      <td>0.600228</td>\n",
              "      <td>0.187828</td>\n",
              "      <td>-1.127004</td>\n",
              "      <td>-1.379635</td>\n",
              "      <td>0.376566</td>\n",
              "      <td>0.943147</td>\n",
              "      <td>-1.799694</td>\n",
              "      <td>0.341880</td>\n",
              "      <td>0.669573</td>\n",
              "      <td>0.474893</td>\n",
              "      <td>0.325464</td>\n",
              "      <td>-0.656118</td>\n",
              "      <td>-4.472616</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>0.029039</td>\n",
              "      <td>0.871993</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.437457</td>\n",
              "      <td>-0.185603</td>\n",
              "      <td>-0.531825</td>\n",
              "      <td>-1.030433</td>\n",
              "      <td>-1.070651</td>\n",
              "      <td>-1.030433</td>\n",
              "      <td>-0.340001</td>\n",
              "      <td>0.695359</td>\n",
              "      <td>0.001732</td>\n",
              "      <td>1.101626</td>\n",
              "      <td>1.112870</td>\n",
              "      <td>0.197559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-06-30</th>\n",
              "      <td>0.380572</td>\n",
              "      <td>0.498842</td>\n",
              "      <td>0.497501</td>\n",
              "      <td>-0.368401</td>\n",
              "      <td>-0.832170</td>\n",
              "      <td>-0.718926</td>\n",
              "      <td>2.413005</td>\n",
              "      <td>-2.316038</td>\n",
              "      <td>1.629837</td>\n",
              "      <td>1.387319</td>\n",
              "      <td>0.369877</td>\n",
              "      <td>0.664783</td>\n",
              "      <td>0.589723</td>\n",
              "      <td>0.664499</td>\n",
              "      <td>0.340542</td>\n",
              "      <td>0.428406</td>\n",
              "      <td>-0.651949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.379096</td>\n",
              "      <td>0.534949</td>\n",
              "      <td>0.211466</td>\n",
              "      <td>0.571904</td>\n",
              "      <td>-0.286711</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.422618</td>\n",
              "      <td>-0.778138</td>\n",
              "      <td>-0.091403</td>\n",
              "      <td>0.414003</td>\n",
              "      <td>-1.390509</td>\n",
              "      <td>0.414545</td>\n",
              "      <td>0.574648</td>\n",
              "      <td>0.417028</td>\n",
              "      <td>0.447807</td>\n",
              "      <td>-0.580025</td>\n",
              "      <td>-0.296105</td>\n",
              "      <td>0.325422</td>\n",
              "      <td>-0.368840</td>\n",
              "      <td>0.874210</td>\n",
              "      <td>-0.658834</td>\n",
              "      <td>0.476669</td>\n",
              "      <td>0.215313</td>\n",
              "      <td>-0.721033</td>\n",
              "      <td>-0.762729</td>\n",
              "      <td>0.241035</td>\n",
              "      <td>0.815403</td>\n",
              "      <td>-1.818672</td>\n",
              "      <td>0.341880</td>\n",
              "      <td>0.732565</td>\n",
              "      <td>0.503154</td>\n",
              "      <td>0.325464</td>\n",
              "      <td>-0.656118</td>\n",
              "      <td>-4.472616</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>-1.08</td>\n",
              "      <td>0.040753</td>\n",
              "      <td>0.871993</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.244354</td>\n",
              "      <td>-0.192681</td>\n",
              "      <td>-0.203943</td>\n",
              "      <td>-0.381831</td>\n",
              "      <td>-0.918247</td>\n",
              "      <td>-0.381831</td>\n",
              "      <td>-0.533502</td>\n",
              "      <td>0.690014</td>\n",
              "      <td>0.024020</td>\n",
              "      <td>0.944556</td>\n",
              "      <td>0.955088</td>\n",
              "      <td>0.380572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-07-01</th>\n",
              "      <td>0.481933</td>\n",
              "      <td>0.502769</td>\n",
              "      <td>0.623434</td>\n",
              "      <td>-0.440365</td>\n",
              "      <td>-0.470215</td>\n",
              "      <td>-0.345844</td>\n",
              "      <td>1.078376</td>\n",
              "      <td>-0.173537</td>\n",
              "      <td>1.190982</td>\n",
              "      <td>1.419374</td>\n",
              "      <td>0.394061</td>\n",
              "      <td>0.594807</td>\n",
              "      <td>0.585601</td>\n",
              "      <td>0.659894</td>\n",
              "      <td>0.338077</td>\n",
              "      <td>0.425923</td>\n",
              "      <td>-0.474363</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.371012</td>\n",
              "      <td>0.523445</td>\n",
              "      <td>0.206970</td>\n",
              "      <td>0.554088</td>\n",
              "      <td>-0.073213</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.422996</td>\n",
              "      <td>-0.609038</td>\n",
              "      <td>-0.059761</td>\n",
              "      <td>0.334861</td>\n",
              "      <td>-1.055813</td>\n",
              "      <td>0.427682</td>\n",
              "      <td>0.597917</td>\n",
              "      <td>0.440469</td>\n",
              "      <td>0.468953</td>\n",
              "      <td>-0.649149</td>\n",
              "      <td>-0.225692</td>\n",
              "      <td>0.220698</td>\n",
              "      <td>0.301190</td>\n",
              "      <td>0.615624</td>\n",
              "      <td>-0.143383</td>\n",
              "      <td>0.378313</td>\n",
              "      <td>0.191651</td>\n",
              "      <td>-0.455994</td>\n",
              "      <td>0.545523</td>\n",
              "      <td>0.130407</td>\n",
              "      <td>0.683833</td>\n",
              "      <td>-1.746054</td>\n",
              "      <td>0.341880</td>\n",
              "      <td>0.768560</td>\n",
              "      <td>0.519303</td>\n",
              "      <td>0.325464</td>\n",
              "      <td>-0.547110</td>\n",
              "      <td>-4.208396</td>\n",
              "      <td>-0.733333</td>\n",
              "      <td>1.214286</td>\n",
              "      <td>-1.08</td>\n",
              "      <td>0.052232</td>\n",
              "      <td>0.871993</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.141173</td>\n",
              "      <td>-0.181815</td>\n",
              "      <td>-0.122669</td>\n",
              "      <td>-0.145640</td>\n",
              "      <td>-0.493750</td>\n",
              "      <td>-0.145640</td>\n",
              "      <td>-0.530201</td>\n",
              "      <td>0.688926</td>\n",
              "      <td>-0.038492</td>\n",
              "      <td>0.461642</td>\n",
              "      <td>0.468134</td>\n",
              "      <td>0.481933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-07-02</th>\n",
              "      <td>0.562178</td>\n",
              "      <td>0.415700</td>\n",
              "      <td>0.744058</td>\n",
              "      <td>-0.571975</td>\n",
              "      <td>-0.223002</td>\n",
              "      <td>0.068670</td>\n",
              "      <td>1.526921</td>\n",
              "      <td>0.516853</td>\n",
              "      <td>0.484789</td>\n",
              "      <td>1.444752</td>\n",
              "      <td>0.428962</td>\n",
              "      <td>0.568728</td>\n",
              "      <td>0.587761</td>\n",
              "      <td>0.662586</td>\n",
              "      <td>0.339099</td>\n",
              "      <td>0.428003</td>\n",
              "      <td>-0.342395</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.379722</td>\n",
              "      <td>0.538739</td>\n",
              "      <td>0.209218</td>\n",
              "      <td>0.589969</td>\n",
              "      <td>0.054650</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.422798</td>\n",
              "      <td>-0.475166</td>\n",
              "      <td>-0.005646</td>\n",
              "      <td>0.283012</td>\n",
              "      <td>-0.731480</td>\n",
              "      <td>0.424918</td>\n",
              "      <td>0.615613</td>\n",
              "      <td>0.472877</td>\n",
              "      <td>0.495844</td>\n",
              "      <td>-0.697918</td>\n",
              "      <td>-0.014569</td>\n",
              "      <td>0.070872</td>\n",
              "      <td>0.445577</td>\n",
              "      <td>0.210036</td>\n",
              "      <td>0.145942</td>\n",
              "      <td>0.305676</td>\n",
              "      <td>0.166799</td>\n",
              "      <td>-0.239481</td>\n",
              "      <td>0.252244</td>\n",
              "      <td>0.118046</td>\n",
              "      <td>0.565567</td>\n",
              "      <td>-1.403671</td>\n",
              "      <td>0.368178</td>\n",
              "      <td>0.768560</td>\n",
              "      <td>0.534444</td>\n",
              "      <td>0.325464</td>\n",
              "      <td>-0.512287</td>\n",
              "      <td>-4.123992</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>-1.08</td>\n",
              "      <td>0.063482</td>\n",
              "      <td>0.871993</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.059341</td>\n",
              "      <td>-0.160096</td>\n",
              "      <td>-0.188087</td>\n",
              "      <td>0.035987</td>\n",
              "      <td>-0.131324</td>\n",
              "      <td>0.035987</td>\n",
              "      <td>-0.437596</td>\n",
              "      <td>0.688528</td>\n",
              "      <td>-0.402588</td>\n",
              "      <td>0.337031</td>\n",
              "      <td>0.342025</td>\n",
              "      <td>0.562178</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Close  volume_adi  volume_obv  ...  others_dr  others_dlr  others_cr\n",
              "Date                                          ...                                  \n",
              "2020-06-26 -0.009386    0.262485    0.161485  ...  -2.097074   -2.159749  -0.009386\n",
              "2020-06-29  0.197559    0.407038    0.300251  ...   1.101626    1.112870   0.197559\n",
              "2020-06-30  0.380572    0.498842    0.497501  ...   0.944556    0.955088   0.380572\n",
              "2020-07-01  0.481933    0.502769    0.623434  ...   0.461642    0.468134   0.481933\n",
              "2020-07-02  0.562178    0.415700    0.744058  ...   0.337031    0.342025   0.562178\n",
              "\n",
              "[5 rows x 73 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8_g407PqYnB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6f160506-2cf3-4d9f-b7e6-202c806396bb"
      },
      "source": [
        "## Datetime conversion\n",
        "df['Date'] = pd.to_datetime(df.Date)\n",
        "\n",
        "# Setting the index\n",
        "df.set_index('Date', inplace=True)\n",
        "\n",
        "# Dropping any NaNs\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "## Technical Indicators\n",
        "\n",
        "# Adding all the indicators\n",
        "df = ta.add_all_ta_features(df, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\", fillna=True)\n",
        "\n",
        "# Dropping everything else besides 'Close' and the Indicators\n",
        "df.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1, inplace=True)\n",
        "\n",
        "# Only using the last 1000 days of data to get a more accurate representation of the current market climate\n",
        "df = df.tail(1000)\n",
        "\n",
        "\n",
        "\n",
        "## Scaling\n",
        "\n",
        "# Scale fitting the close prices separately for inverse_transformations purposes later\n",
        "close_scaler = RobustScaler()\n",
        "\n",
        "close_scaler.fit(df[['Close']])\n",
        "\n",
        "# Normalizing/Scaling the DF\n",
        "scaler = RobustScaler()\n",
        "\n",
        "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ta/trend.py:608: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dip[i] = 100 * (self._dip[i]/self._trs[i])\n",
            "/usr/local/lib/python3.6/dist-packages/ta/trend.py:612: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  din[i] = 100 * (self._din[i]/self._trs[i])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhVQUUEqqsAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_sequence(seq, n_steps_in, n_steps_out):\n",
        "    \"\"\"\n",
        "    Splits the multivariate time sequence\n",
        "    \"\"\"\n",
        "    \n",
        "    # Creating a list for both variables\n",
        "    X, y = [], []\n",
        "    \n",
        "    for i in range(len(seq)):\n",
        "        \n",
        "        # Finding the end of the current sequence\n",
        "        end = i + n_steps_in\n",
        "        out_end = end + n_steps_out\n",
        "        \n",
        "        # Breaking out of the loop if we have exceeded the dataset's length\n",
        "        if out_end > len(seq):\n",
        "            break\n",
        "        \n",
        "        # Splitting the sequences into: x = past prices and indicators, y = prices ahead\n",
        "        seq_x, seq_y = seq[i:end, :], seq[end:out_end, 0]\n",
        "        \n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    \n",
        "    return np.array(X), np.array(y)\n",
        "  \n",
        "  \n",
        "def visualize_training_results(results):\n",
        "    \"\"\"\n",
        "    Plots the loss and accuracy for the training and testing data\n",
        "    \"\"\"\n",
        "    history = results.history\n",
        "    plt.figure(figsize=(16,5))\n",
        "    plt.plot(history['val_loss'])\n",
        "    plt.plot(history['loss'])\n",
        "    plt.legend(['val_loss', 'loss'])\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure(figsize=(16,5))\n",
        "    plt.plot(history['val_accuracy'])\n",
        "    plt.plot(history['accuracy'])\n",
        "    plt.legend(['val_accuracy', 'accuracy'])\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "def layer_maker(n_layers, n_nodes, activation, drop=None, d_rate=.5):\n",
        "    \"\"\"\n",
        "    Creates a specified number of hidden layers for an RNN\n",
        "    Optional: Adds regularization option - the dropout layer to prevent potential overfitting (if necessary)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Creating the specified number of hidden layers with the specified number of nodes\n",
        "    for x in range(1,n_layers+1):\n",
        "        model.add(LSTM(n_nodes, activation=activation, return_sequences=True))\n",
        "\n",
        "        # Adds a Dropout layer after every Nth hidden layer (the 'drop' variable)\n",
        "        try:\n",
        "            if x % drop == 0:\n",
        "                model.add(Dropout(d_rate))\n",
        "        except:\n",
        "            pass\n",
        "          \n",
        "          \n",
        "def validater(n_per_in, n_per_out):\n",
        "    \"\"\"\n",
        "    Runs a 'For' loop to iterate through the length of the DF and create predicted values for every stated interval\n",
        "    Returns a DF containing the predicted values for the model with the corresponding index values based on a business day frequency\n",
        "    \"\"\"\n",
        "    \n",
        "    # Creating an empty DF to store the predictions\n",
        "    predictions = pd.DataFrame(index=df.index, columns=[df.columns[0]])\n",
        "\n",
        "    for i in range(n_per_in, len(df)-n_per_in, n_per_out):\n",
        "        # Creating rolling intervals to predict off of\n",
        "        x = df[-i - n_per_in:-i]\n",
        "\n",
        "        # Predicting using rolling intervals\n",
        "        yhat = model.predict(np.array(x).reshape(1, n_per_in, n_features))\n",
        "\n",
        "        # Transforming values back to their normal prices\n",
        "        yhat = close_scaler.inverse_transform(yhat)[0]\n",
        "\n",
        "        # DF to store the values and append later, frequency uses business days\n",
        "        pred_df = pd.DataFrame(yhat, \n",
        "                               index=pd.date_range(start=x.index[-1], \n",
        "                                                   periods=len(yhat), \n",
        "                                                   freq=\"B\"),\n",
        "                               columns=[x.columns[0]])\n",
        "\n",
        "        # Updating the predictions DF\n",
        "        predictions.update(pred_df)\n",
        "        \n",
        "    return predictions\n",
        "\n",
        "\n",
        "def val_rmse(df1, df2):\n",
        "    \"\"\"\n",
        "    Calculates the root mean square error between the two Dataframes\n",
        "    \"\"\"\n",
        "    df = df1.copy()\n",
        "    \n",
        "    # Adding a new column with the closing prices from the second DF\n",
        "    df['close2'] = df2.Close\n",
        "    \n",
        "    # Dropping the NaN values\n",
        "    df.dropna(inplace=True)\n",
        "    \n",
        "    # Adding another column containing the difference between the two DFs' closing prices\n",
        "    df['diff'] = df.Close - df.close2\n",
        "    \n",
        "    # Squaring the difference and getting the mean\n",
        "    rms = (df[['diff']]**2).mean()\n",
        "    \n",
        "    # Returning the sqaure root of the root mean square\n",
        "    return float(np.sqrt(rms))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgOcHTRlq39x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How many periods looking back to learn\n",
        "n_per_in  = 90\n",
        "# How many periods to predict\n",
        "n_per_out = 30\n",
        "# Features \n",
        "n_features = df.shape[1]\n",
        "# Splitting the data into appropriate sequences\n",
        "X, y = split_sequence(df.to_numpy(), n_per_in, n_per_out)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki6IjXTOq-dN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a065e0e4-835d-4547-ef26-f290f98d22e2"
      },
      "source": [
        "## Creating the NN\n",
        "\n",
        "# Instatiating the model\n",
        "model = Sequential()\n",
        "\n",
        "# Activation\n",
        "activ = \"tanh\"\n",
        "\n",
        "# Input layer\n",
        "model.add(LSTM(90, \n",
        "               activation=activ, \n",
        "               return_sequences=True, \n",
        "               input_shape=(n_per_in, n_features)))\n",
        "\n",
        "# Hidden layers\n",
        "layer_maker(n_layers=1, \n",
        "            n_nodes=30, \n",
        "            activation=activ)\n",
        "\n",
        "# Final Hidden layer\n",
        "model.add(LSTM(60, activation=activ))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(n_per_out))\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Compiling the data with selected specifications\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "\n",
        "## Fitting and Training\n",
        "res = model.fit(X, y, epochs=50, batch_size=128, validation_split=0.1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1e956c489d30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactiv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                input_shape=(n_per_in, n_features)))\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Hidden layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 raise ValueError('Layer ' + self.name + ' was called with '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \"\"\"\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[1;32m    697\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_TensorLike\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dense_tensor_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'"
          ]
        }
      ]
    }
  ]
}